<h1><center> Modernizing Grand Central Dispatch Usage(1) </center></h1>

###### tags: `ğŸ’» WWDC ìŠ¤í„°ë””`, `ğŸ’» TIL`
###### date: `2024-01-03T15:12:33.284Z`

> [color=#724cd1][name=ë°ë¦­]
> [Modernizing Grand Central Dispatch Usage - wwdc17](https://developer.apple.com/videos/play/wwdc2017/706/)

> WWDC 2017 Session ì¤‘ í•˜ë‚˜ì¸ `Modernizing Grand Central Dispatch Usage`ì— ëŒ€í•´ ì•Œì•„ë³´ì

# ê°œìš” 

> 2023ë…„ 6ì›”ì— ê³µë¶€í•˜ë‹¤ê°€ ë§ì•˜ë˜ WWDCë¥¼ ë§ˆë¬´ë¦¬í•˜ê³ ì í•œë‹¤. ì˜ˆì „ì—ëŠ” ë‹¤ìŒ ì‹œê°„ì— ë‚˜ë¨¸ì§€ë¥¼ ê³µë¶€í•´ì•¼ì§€ í•˜ê³  ìƒê°ë§Œí•´ì„œ ìŠê³  ì§€ëƒˆì—ˆë‹¤. í•˜ì§€ë§Œ, ì‘ë…„ 11ì›”ë¶€í„° ìƒˆë¡­ê²Œ ì¥ì°©í•œ ë§ˆì¸ë“œë¡œ ì¸í•´ ë§¤ì£¼ ìˆ˜ìš”ì¼ WWDCë¥¼ í•™ìŠµí•´ì•¼ í•˜ëŠ” ìŠ¤ì¼€ì¥´ì„ ë§Œë“¤ì—ˆë‹¤. ì´ì œ ë‚˜ë¨¸ì§€ ê³µë¶€ëŠ” ì—†ë‹¤. ê·¸ëƒ¥ ê¾¸ì¤€íˆ í•˜ì.<br>

## Modernizing GCD Usage

GCDëŠ” Single Coreì¸ Apple Watchë¶€í„° mini Coreì¸ Macê¹Œì§€ ì•±ì˜ ì½”ë“œë¥¼ ë™ì ìœ¼ë¡œ í™•ì¥í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆë‹¤. ê·¼ë° ì–´ë–¤ ì¢…ë¥˜ì˜ í•˜ë“œì›¨ì–´ë¥¼ ì‹¤í–‰í•˜ê³  ìˆëŠ”ì§€ì— ëŒ€í•´ ë„ˆë¬´ ê±±ì •í•  í•„ìš”ê°€ ì—†ë‹¤ê³  í•œë‹¤.

```
But there are problematic problems that can affect the scalability and the efficiency of your code
```
? 

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2024-01-03 20.24.05](https://hackmd.io/_uploads/ByWJVaGOT.png)

GCD API í˜¹ì€ ë‹¤ë¥¸ APIë“¤ì„ ì‚¬ìš©í•´ì„œ íë¥¼ ë§Œë“¤ê³  ì‹œìŠ¤í…œì— ì‘ì—…ì„ í•˜ë„ë¡ dispatchí–ˆì„ ìˆ˜ ìˆë‹¤. ê·¼ë° ì´ëŸ° ê²ƒë“¤ì€ Grand Central Dispatchë¼ê³  í•˜ëŠ”ë° ì´ëŠ” Concurrency ì¸í„°í˜ì´ìŠ¤ì˜ ì¼ë¶€ì¼ ë¿ì´ë‹¤.

### Efficiency Through Observation

> Going off core during an operation reduces efficiency

ì½”ì–´ë“¤ì´ ë‚˜ë‚ ì´ ë°œì „í–ˆë‹¤ê³  ë§í•˜ëŠ”ë°, ì½”ë“œê°€ ì‘ì—…ì„ ì™„ë£Œí•˜ê¸° ì „ì— ì½”ì–´ì—ì„œ ë²—ì–´ë‚˜ë©´ ì´ì „ì— ì‘ì—…í•œ ë‚´ìš©ì„ ë” ì´ìƒ í™œìš©í•˜ì§€ ëª»í•˜ëŠ” ìƒí™©ì´ ìˆì„ ìˆ˜ ìˆë‹¤. í˜¹ì€, ì½”ì–´ì— ë‹¤ì‹œ ëŒì•„ì˜¬ ë•Œ ì„±ëŠ¥ì´ ì†í•´ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```
And you might leave performance on the table when you come back on core.
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2024-01-03 20.30.38](https://hackmd.io/_uploads/BJ_wBpMu6.png)

ì´ ê·¸ë˜í”„ëŠ” ìœ„ì˜ ìƒí™©ì—ì„œ ë°œìƒí•˜ëŠ” ë¬¸ì œë“¤ì„ ìµœì í™”í•˜ëŠ” ê¸°ìˆ ì„ í†µí•˜ë©´ íš¨ìœ¨ì„±ì´ í¬ê²Œ í–¥ìƒëœë‹¤ëŠ” ë§ì´ë‹¤. 
ì¤‘ìš”í•œ ë‚´ìš©ì€ ì•„ë˜ì— ìˆë‹¤.

- Parallelism and concurrency
    - ë³‘ë ¬ì„±ê³¼ ë™ì‹œì„±ì„ ê°€ì¥ ì˜ í‘œí˜„í•  ìˆ˜ ìˆëŠ” ë°©ë²•
- Using GCD for concurrency
    - Grand Central Dispatchë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ì‹œì„±ì„ í‘œí˜„í•˜ê¸° ìœ„í•´ ê°€ì¥ ì¢‹ì€ ë°©ë²•ì„ ì„ íƒí•˜ëŠ” ë°©ë²•
- Unified Queue Identity
    - GCDì˜ ì£¼ìš” ê°œì„  ì‚¬í•­ì´ë¼ê³  í•œë‹¤.
- Finding problem spots
    - instrumentsë¥¼ ì‚¬ìš©í•´ì„œ ì½”ë“œì—ì„œ ìˆëŠ” ë¬¸ì œ ì§€ì ì„ ì°¾ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤„ê±°ë€ë‹¤.

How you can chose the best way to express concurrency to grand central dispatch.


## Parallelism and Concurrency

**Parallelism**

> Simultaneous execution of closely related computations

-> ê°„ë‹¨í•˜ê²Œ ì—¬ëŸ¬ ì½”ì–´ê°€ í•„ìš”í•˜ê³  ë™ì‹œì— ê·¸ ì½”ì–´ë“¤ì„ ì‚¬ìš©í•˜ê³  ì‹¶ì„ ë•Œë‹¤.

**Concurrency**

> Composition of independently executed tasks

-> Single Coreì—ì„œë„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.

### Parallelism

ì•±ì´ ìˆì„ ë•Œ, ê·¸ ì•ˆì—ì„œ ì‚¬ì´ì¦ˆê°€ ì—„ì²­ í° ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•œë‹¤ê³  ê°€ì •í•´ë³´ì. ê·¸ë¦¬ê³  ì´ í° ì´ë¯¸ì§€ë¥¼ Mac Proì˜ ì½”ì–´ë“¤ì„ í™œìš©í•´ì„œ ë” ë¹ ë¥´ê²Œ ì²˜ë¦¬í•˜ê³  ì‹¶ë‹¤ëŠ” ìƒê°ì´ ë“¤ì—ˆë‹¤. 

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2024-01-03 20.41.58](https://hackmd.io/_uploads/HyJUOpzda.png)

-> ì´ë¯¸ì§€ë¥¼ ë©ì–´ë¦¬ë¡œ ë‚˜ëˆ .?

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2024-01-03 20.43.40](https://hackmd.io/_uploads/r1iF_afO6.png)
  
-> ê·¸ë¦¬ê³  ê° ì½”ì–´ê°€ ì´ ë©ì–´ë¦¬ë“¤ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•˜ê²Œ í•œë‹¤. 

> This gives you a speed up, because the cores are simultaneously working on different parts of the image

ë³‘ë ¬ ì²˜ë¦¬ë¥¼ í†µí•´ ì´ë¯¸ì§€ë¥¼ ë™ì‹œì— ì—¬ëŸ¬ ë¶€ë¶„ì—ì„œ ì²˜ë¦¬í•¨ìœ¼ë¡œì¨ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆë‹¤.

**ê·¸ëŸ¼ ì´ê±¸ ì–´ë–»ê²Œ ì½”ë“œë¡œ êµ¬í˜„í•´?**

**Take Advantange of System Frameworks**

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2024-01-03 20.45.52](https://hackmd.io/_uploads/BycMFpGOT.png)

ë³‘ë ¬ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ì—¬ëŸ¬ í”„ë ˆì„ì›Œí¬ê°€ ìˆëŠ”ë° í•œë²ˆ ë³´ì. 

**Accelerate**

> advanced Image algorithmì˜ ë³‘ë ¬ executionì„ ì§€ì›í•˜ëŠ” ê¸°ëŠ¥ì´ ìˆë‹¤.

**Metal && Core**

> GPUë¥¼ í™œìš©í•  ìˆ˜ ìˆë‹¤.

ê·¼ë° GCDëŠ” ì´ê±¸ ì‰½ê²Œ í‘œí˜„í•  ìˆ˜ ìˆëŠ” Toolì„ ì œê³µí•œë‹¤ê³  í•œë‹¤. 

GCDì—ì„œ ë³‘ë ¬ì„±ì„ í‘œí˜„í•˜ëŠ” ë°©ë²•ì€ **ConcurrentPerform API**ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ë‹¤.

- Express explicit parallelism with `DispatchQueue.concurrentPerform`
- Parallel for-loop--calling thread participates in the computation
- More efficient than many asyncs to a concurrent queue

```swift
DispatchQueue.concurrentPerform(1000) { i in 
    /* iteration */
}
```

ì´ í”„ë ˆì„ì›Œí¬ëŠ” ì½”ì–´ì—ì„œ ë³‘ë ¬ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê¸¸ ì›í•˜ëŠ” ê²ƒì„ ì•Œê³  ìˆì–´ì„œ Parallelismì„ ìµœì í™”í•  ìˆ˜ ìˆë‹¤ê³  í•œë‹¤. 

concurrentPerformëŠ” ì‹œìŠ¤í…œì˜ ëª¨ë“  ì½”ì–´ì— ìë™ìœ¼ë¡œ ì‘ì—… ë¶€í•˜ë¥¼ ë¶„ì‚°í•˜ëŠ” ë³‘ë ¬ for ë£¨í”„ì…ë‹ˆë‹¤.

> concurrentPerform is a parallel for loop that automatically load balances your computation across all the cores in the system.

```swift
dispatch_apply(DISPATCH_APPLY_AUTO, 1000, ^(size_t i)) {
    /* iteration */
}
```

Objective-Cì—ì„œë„ ë™ì¼í•œ ê¸°ëŠ¥ì´ ìˆë‹¤ê³  í•œë‹¤. 

#### Dynamic Resource Availability

> Choosing an iteration count

Three-Core systemì—ì„œ workloadê°€ ì‹¤í–‰ëœë‹¤ê³  ê°€ì •í•´ë³´ì.

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2024-01-03 21.17.10](https://hackmd.io/_uploads/BkWLl0z_6.png)

```swift 
DispatchQueue.concurrentPerform(3) { i in 
    /* iteration */
}
```

ì´ë¯¸ì§€ì—ëŠ” ì„¸ ê°œì˜ blockì´ ì„¸ ê°œì˜ ì½”ì–´ì—ì„œ ë²™ë ¬ë¡œ ì‹¤í–‰ë˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.(ideal caseë‹¤..)

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2024-01-03 21.19.04](https://hackmd.io/_uploads/HkmTx0zup.png)

**UI Renderingìœ¼ë¡œ 3ë²ˆì§¸ ì½”ì–´ë¥¼ ì ì‹œ ì°¨ì§€í•˜ë©´ ì–´ë–»ê²Œ ë ê¹Œ?**

ì„¸ ë²ˆì§¸ ì½”ì–´ê°€ ì ì‹œ UI ë Œë”ë§ì— ì‚¬ìš©ë˜ëŠ” ìƒí™©ì„ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ê·¸ëŸ° ê²½ìš° ë¡œë“œ ë°¸ëŸ°ì„œê°€ í•´ë‹¹ ì„¸ ë²ˆì§¸ ë¸”ë¡ì„ ì‹¤í–‰í•˜ê¸° ìœ„í•´ ê·¸ ë¸”ë¡ì„ ì²« ë²ˆì§¸ ì½”ì–´ë¡œ ì´ë™ì‹œì¼œì•¼ í•œë‹¤ê³  í•œë‹¤..

ì´ ë§¥ë½ì—ì„œ "load balancer"ëŠ” ì‘ì—…ì„ ì—¬ëŸ¬ ì½”ì–´ì— ë¶„ì‚°ì‹œí‚¤ëŠ” ì—­í• ì„ í•˜ëŠ”ë°, ì„¸ ë²ˆì§¸ ì½”ì–´ê°€ UI ë Œë”ë§ ë“± ë‹¤ë¥¸ ì‘ì—…ì— ì‚¬ìš©ë˜ë©´ì„œ í•´ë‹¹ ì½”ì–´ì—ì„œì˜ ì‘ì—…ì´ ì¤‘ë‹¨ëœ ê²½ìš°, ë¡œë“œ ë°¸ëŸ°ì„œëŠ” ì´ ì‘ì—…ì„ ë‹¤ë¥¸ ì‚¬ìš© ê°€ëŠ¥í•œ ì½”ì–´ë¡œ ì´ë™ì‹œì¼œ ì „ì²´ ì„±ëŠ¥ì„ ìœ ì§€í•˜ë ¤ê³  í•©ë‹ˆë‹¤. ì´ëŠ” ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìµœëŒ€í•œ í™œìš©í•˜ê³  ì„±ëŠ¥ì„ ìµœì í™”í•˜ê¸° ìœ„í•œ ë°©ë²• ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.

> What might happens if the third core is taken up for awhile with UI rendering? Well, what happens is the load balancer has to move that third block over to the first core in order to execute it, because it's the third course taken up.

7:57